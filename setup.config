# main configuration to setup the network
# usage - call by multiNodeLearning.py file
# to save different setting to run expect results


[Networks]
# ToDo Legacy with Random <<<<
# The type of each node 
# 0 - Legacy (Dumb) Node 
# 1 - Hopping Node
# 2 - Intermittent Node/ im Node
# 3 - DSA node (just avoids) 
# 4 - poisson Node 
# 5 - MDP Node
# 6 - a. DQN Node
# 7 - b. DQN-DoubleQ
# 8 - c. DQN-PriReplay
# 9 - d. DQN-Duel     
# 10 - dpg Node
# - Adv. MDP Node(ToDo)



numSteps = 10000
numChans = 3
ChannelAssignType = typeIn  

nodeTypes = [0, 0, 6]

legacyChanList   = [0, 1]
txProbability    = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hoppingChanList  = [ [2, 3] ]
hoppingWidth     = 2
hopRate     = 10
imChanList       = [2]                      
imDutyCircleList = [0.2, 0.8] 

poissonChanList  = 2 
arrivalRate       = 10
serviceRate      = 8


# test case to test "learning hidden" nodeTypes = [0,0,5,5] where 3rd & 4th is duplex conflict
# test case to test "learning spatial" nodeTypes = [0,0,0,5,5] where 4rd & 5th is duplex conflict


[Neural Network]
# in dqnxx.py mdp.py
# Set "explore ratio" - exploreTye, exploreDecay, exploreProbMin
# set "reward"

